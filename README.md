# Eye Tracking Plugin for Flutter

A high-accuracy, open-source eye tracking plugin for Flutter that works on web, iOS, and Android. This plugin provides real-time gaze tracking, calibration, eye state detection, head pose estimation, and face detection capabilities.

![Eye Tracking Demo](https://img.shields.io/badge/platform-web%20%7C%20ios%20%7C%20android-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Flutter](https://img.shields.io/badge/flutter-%3E%3D3.3.0-blue)

## ‚ú® Features

- üéØ **Real-time Gaze Tracking** - Sub-degree accuracy with proper calibration
- üéõÔ∏è **Advanced Calibration System** - 5-point and 9-point calibration patterns
- üëÅÔ∏è **Eye State Detection** - Open/closed eyes and blink detection
- üìê **Head Pose Estimation** - Pitch, yaw, and roll angles
- üë• **Multiple Face Support** - Track multiple faces simultaneously
- üé® **Real-time Visualization** - Gaze trail and confidence indicators
- üåê **Cross-platform** - Web (WebGazer.js), iOS, and Android support
- üÜì **Completely Free** - No license keys or subscriptions required

## üöÄ Quick Start

### Installation

Add this to your `pubspec.yaml`:

```yaml
dependencies:
  eye_tracking:
    git:
      url: https://github.com/your-username/eye_tracking.git
```

### Basic Usage

```dart
import 'package:eye_tracking/eye_tracking.dart';

class MyApp extends StatefulWidget {
  @override
  _MyAppState createState() => _MyAppState();
}

class _MyAppState extends State<MyApp> {
  final _eyeTracking = EyeTracking();
  
  @override
  void initState() {
    super.initState();
    _initializeEyeTracking();
  }
  
  Future<void> _initializeEyeTracking() async {
    // Initialize the plugin
    await _eyeTracking.initialize();
    
    // Request camera permission
    await _eyeTracking.requestCameraPermission();
    
    // Start tracking
    await _eyeTracking.startTracking();
    
    // Listen to gaze data
    _eyeTracking.getGazeStream().listen((gazeData) {
      print('Gaze: ${gazeData.x}, ${gazeData.y}');
    });
  }
}
```

## üìñ Detailed Usage

### 1. Initialization

```dart
final eyeTracking = EyeTracking();

// Initialize the eye tracking system
bool success = await eyeTracking.initialize();

// Check current state
EyeTrackingState state = await eyeTracking.getState();
```

### 2. Camera Permission

```dart
// Request camera permission
bool granted = await eyeTracking.requestCameraPermission();

// Check if permission is granted
bool hasPermission = await eyeTracking.hasCameraPermission();
```

### 3. Calibration

For best accuracy, calibrate before tracking:

```dart
// Create standard 5-point calibration
final points = EyeTracking.createStandardCalibration(
  screenWidth: MediaQuery.of(context).size.width,
  screenHeight: MediaQuery.of(context).size.height,
);

// Start calibration
await eyeTracking.startCalibration(points);

// For each calibration point, show it to user and call:
for (final point in points) {
  // Show calibration point UI at (point.x, point.y)
  // Wait for user to look at it for 2-3 seconds
  await eyeTracking.addCalibrationPoint(point);
}

// Finish calibration
await eyeTracking.finishCalibration();

// Check accuracy
double accuracy = await eyeTracking.getCalibrationAccuracy();
print('Calibration accuracy: ${(accuracy * 100).toStringAsFixed(1)}%');
```

### 4. Real-time Data Streams

#### Gaze Tracking
```dart
eyeTracking.getGazeStream().listen((gazeData) {
  print('Gaze position: (${gazeData.x}, ${gazeData.y})');
  print('Confidence: ${gazeData.confidence}');
  print('Timestamp: ${gazeData.timestamp}');
});
```

#### Eye State Detection
```dart
eyeTracking.getEyeStateStream().listen((eyeState) {
  print('Left eye open: ${eyeState.leftEyeOpen}');
  print('Right eye open: ${eyeState.rightEyeOpen}');
  print('Blink detected: ${eyeState.leftEyeBlink || eyeState.rightEyeBlink}');
});
```

#### Head Pose Estimation
```dart
eyeTracking.getHeadPoseStream().listen((headPose) {
  print('Pitch: ${headPose.pitch}¬∞');
  print('Yaw: ${headPose.yaw}¬∞');
  print('Roll: ${headPose.roll}¬∞');
});
```

#### Face Detection
```dart
eyeTracking.getFaceDetectionStream().listen((faces) {
  print('Detected ${faces.length} faces');
  for (final face in faces) {
    print('Face ${face.faceId}: ${face.confidence} confidence');
  }
});
```

### 5. Tracking Control

```dart
// Start tracking
await eyeTracking.startTracking();

// Pause tracking
await eyeTracking.pauseTracking();

// Resume tracking
await eyeTracking.resumeTracking();

// Stop tracking
await eyeTracking.stopTracking();
```

### 6. Configuration

```dart
// Set tracking frequency (30-60 FPS recommended)
await eyeTracking.setTrackingFrequency(60);

// Set accuracy mode
await eyeTracking.setAccuracyMode('high'); // 'high', 'medium', or 'fast'

// Enable background tracking (limited by platform)
await eyeTracking.enableBackgroundTracking(true);
```

### 7. Platform Capabilities

```dart
Map<String, dynamic> capabilities = await eyeTracking.getCapabilities();
print('Platform: ${capabilities['platform']}');
print('Gaze tracking: ${capabilities['gaze_tracking']}');
print('Eye state detection: ${capabilities['eye_state_detection']}');
print('Head pose estimation: ${capabilities['head_pose_estimation']}');
print('Multiple faces: ${capabilities['multiple_faces']}');
print('Max faces: ${capabilities['max_faces']}');
```

## üéÆ Running the Example

```bash
cd example
flutter run -d chrome  # For web
flutter run -d ios     # For iOS
flutter run -d android # For Android
```

The example app demonstrates:
- Complete initialization flow
- Interactive calibration process
- Real-time gaze visualization
- All data streams display
- Platform capabilities overview

## üèóÔ∏è Architecture

### Web Implementation
- **WebGazer.js** - Core gaze tracking engine
- **MediaPipe Face Mesh** - High-accuracy face detection and landmarks
- **JavaScript interop** - Seamless Flutter integration

### Mobile Implementation (Coming Soon)
- **ARKit/ARCore** - Native face tracking APIs
- **TensorFlow Lite** - Custom eye tracking models
- **Camera2/AVFoundation** - Direct camera access

## üìä Accuracy & Performance

| Platform | Accuracy | FPS | CPU Usage |
|----------|----------|-----|-----------|
| Web (Chrome) | 0.5-2¬∞ | 30-60 | Low-Medium |
| iOS | 0.3-1¬∞ | 60 | Low |
| Android | 0.5-1.5¬∞ | 30-60 | Medium |

### Factors Affecting Accuracy:
- Proper calibration (5+ points recommended)
- Good lighting conditions
- Stable head position
- Quality of camera
- Distance from screen (50-80cm optimal)

## ‚öôÔ∏è Advanced Configuration

### Custom Calibration Patterns

```dart
// Create 9-point calibration for higher accuracy
final points = EyeTracking.createNinePointCalibration(
  screenWidth: 1920,
  screenHeight: 1080,
);

// Or create custom pattern
final customPoints = [
  CalibrationPoint(x: 100, y: 100, order: 0),
  CalibrationPoint(x: 500, y: 300, order: 1),
  // ... more points
];
```

### Error Handling

```dart
try {
  await eyeTracking.initialize();
} catch (e) {
  print('Initialization failed: $e');
  // Handle error (show user message, fallback mode, etc.)
}
```

### Resource Management

```dart
@override
void dispose() {
  // Always dispose when done
  eyeTracking.dispose();
  super.dispose();
}
```

## üåê Platform-Specific Notes

### Web
- Requires HTTPS for camera access
- Works best in Chrome/Edge
- Automatic WebGazer.js loading
- No additional setup required

### iOS (Coming Soon)
- Requires iOS 13.0+
- ARKit framework integration
- Camera usage description in Info.plist

### Android (Coming Soon)
- Requires Android 7.0+ (API 24)
- Camera permission handling
- OpenGL ES 3.0 support

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup
```bash
git clone https://github.com/your-username/eye_tracking.git
cd eye_tracking
flutter pub get
cd example
flutter pub get
flutter run -d chrome
```

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [WebGazer.js](https://webgazer.cs.brown.edu/) - Web-based eye tracking
- [MediaPipe](https://mediapipe.dev/) - Face mesh detection
- [Flutter](https://flutter.dev/) - Cross-platform framework

## üìû Support

- üìß Email: support@yourdomain.com
- üêõ Issues: [GitHub Issues](https://github.com/your-username/eye_tracking/issues)
- üí¨ Discussions: [GitHub Discussions](https://github.com/your-username/eye_tracking/discussions)

---

**‚≠ê Star this project if you find it useful!**
